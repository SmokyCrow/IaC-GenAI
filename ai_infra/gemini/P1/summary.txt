Model: Gemini 2.5 pro
Prompt level: 1
Candidate ID: gemini2.5pro-P1

Base-Prompt:
```
Create Terraform for Docker Desktop Kubernetes (single-node) to deploy the "Semantic Segmenter" app with:
- Namespace: `semseg`
- Deployments: ingest-api, results-api, qa-web, convert-ply, part-labeler, redactor, analytics, redis
- Services: ingest-api, results-api, qa-web, redis

Keep image names as variables and focus on generating the Kubernetes resources via Terraform. Use the default kubeconfig for Docker Desktop (on Windows: `%USERPROFILE%\.kube\config`), but you may accept an optional `kubeconfig` variable. You may assume reasonable service ports, exposure (NodePort vs ClusterIP), and storage details following best practices for Docker Desktop single-node clusters. Apply Terraform best practices for module structure and code quality (clear modules, variables, outputs, pinned providers). Use a shared image variable for workers and web UIs (`shared_image`), a separate image for `ingest-api` (`ingest_image`), and `redis:7-alpine` for Redis. Focus on a working, single-replica deployment; do not include autoscaling (HPA/VPA) or replica tuning. Do not include security hardening (RBAC, PodSecurityPolicy/SCC, NetworkPolicy, Pod/Container securityContext); focus only on the provided information.
At the end, include example Terraform commands to run (fmt, init, validate, apply). For apply, include -var assignments for any variables your solution requires.
```

Scores (1..5):
- Correctness (docker): 
- Kubernetes fit: 
- Storage: 
- Image handling: 
- Networking: 
- Modularity: 
- Observability: 
- Reasoning: 

Overall (avg or weighted): 

Provided structure:
semseg-terraform/
├── semseg-terraform/
│   ├── main.tf                    
│   ├── variables.tf               
│   ├── outputs.tf                 
│   └── versions.tf                          
	  
Extra prompts needed:
1:
The shared image is semantic-segmenter:latest, the ingest-api image is ingest-api:latest, other than ingest-api, and redis, every deployment uses the shared image. The env variables for different deployments:
ingest-api: INGEST_OUT_DIR
results-api: SEGMENTS_DIR, REDIS_URL, REDIS_STREAM_FRAMES_CONVERTED, REDIS_STREAM_PARTS_LABELED, REDIS_STREAM_REDACTED_DONE, REDIS_STREAM_ANALYTICS_DONE
qa-web: RESULTS_API_URL
convert: REDIS_URL, REDIS_STREAM_FRAMES_CONVERTED, PREVIEW_OUT_DIR
labeler: REDIS_URL, REDIS_STREAM_PARTS_LABELED, REDIS_STREAM_FRAMES_CONVERTED, REDIS_GROUP_PART_LABELER
redactor: REDIS_URL, REDIS_STREAM_PARTS_LABELED, REDIS_STREAM_REDACTED_DONE, REDIS_GROUP_REDACTOR
analytics: REDIS_URL, REDIS_STREAM_PARTS_LABELED, REDIS_STREAM_ANALYTICS_DONE, REDIS_GROUP_ANALYTICS
2:
Please fix the env variables based on the information below:
Streams: s_frames_converted, s_parts_labeled, s_redacted_done, s_analytics_done
Groups: g_part_labeler, g_redactor, g_analytics
/sub-pc-frames → PVC sub-pc-frames-pvc
   - Producers/consumers: ingest-api (writes), convert-ply (reads)
/pc-frames → PVC pc-frames-pvc
   - Producers/consumers: convert-ply (writes), part-labeler (reads), redactor (reads)
/segments → PVC segments-pvc
   - Producers/consumers: convert-ply (writes previews), part-labeler (writes labels and colorized), redactor (writes), analytics (writes), results-api (reads)
/segments/labels (subdirectory under /segments)
   - Producer: part-labeler (colorized outputs)
3:
Error: Unsupported argument
  on main.tf line 229, in resource "kubernetes_deployment" "apps":
 229:           env = [
An argument named "env" is not expected here. Did you mean to define a block of type "env"?
Error: Unsupported block type
  on main.tf line 247, in resource "kubernetes_deployment" "apps":
 247:           dynamic "ports" {
Blocks of type "ports" are not expected here.
Fix error.
4:
We also need to add args to some deployments, please do that based on the information provided below:
results-api: uvicorn services.results_api.app:app --host 0.0.0.0 --port 8080 --workers 1
qa-web: uvicorn services.qa_web.app:app --host 0.0.0.0 --port 3000 --workers 1
convert: python3 /semantic-segmenter/services/convert_service/convert-ply --in-dir /sub-pc-frames --out-dir /pc-frames --preview-out-dir /segments --delete-source --log-level info
labeler: python3 /semantic-segmenter/services/part_labeler/part_labeler.py --log-level info --out-dir /segments --colorized-dir /segments/labels --write-colorized
redactor: python3 /semantic-segmenter/services/redactor/redactor.py --log-level info --out-dir /segments
analytics: python3 /semantic-segmenter/services/analytics/analytics.py --log-level info --out-dir /segments
5:
Error: Unsupported attribute
  on main.tf line 288, in resource "kubernetes_deployment" "apps":
 288:               mount_path = volume_mount.value.path
    ├────────────────
    │ volume_mount.value is object with 3 attributes
This object does not have an attribute named "path".
5:
Remove storage_class_name variale as it is unneccessary for this implementation, and not a valid default storage class name. Do not set storage_class_name in pvc's.
6:
Please change image_pull_policy to IfNotPresent because we have the images locally.
7:
Services need to be created before deployments, otherwise it is counterproductive.
8:
Error: Attribute redefined
  on main.tf line 334, in resource "kubernetes_deployment" "apps":
 334:   depends_on = [kubernetes_persistent_volume_claim.main]
The argument "depends_on" was already set at main.tf:232,3-13. Each argument may be set only once.
9:
Error: Cycle: kubernetes_deployment.apps, kubernetes_service.svcs
Remove dependency from svcs.


Notes:
- 1st prompt provided good solution.
- 2nd prompt provided good solution, but introduced errors that were fixed in 3rd prompt.
- 4th prompt provided good solution for the prompt itself, but also introduced some error in part of the implementation that was not related to the commands, this was fixed in 5th prompt. 
- 5th prompt provided good solution.
- manually overwritten default kubeconfig variable.
- 6th prompt provided good solution.
- Noticed missing /0 from the end of redis url, fixed it manually.
- 7th prompt provided some solution but in a wrong way. It introduced double argumenting, and then a cycle. This happened because Gemini decided during extra prompting that it is not going to store the entire tf artifacts just the changes, so it got confused. Part of it was fixed in the 8th prompt. The 9th prompt reverted the 7th prompts change somehow, so I had to manually remove the dependency from the svcs.


Local test apply command:
terraform apply